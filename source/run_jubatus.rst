=====================
 Jubatusを使ってみる
=====================

まずはJubatusを起動して、実際にデータを流すところまで手を動かしてみましょう。
サンプルソースを読み解きながら、どのように使えば良いのかを解説します。


Jubatusを起動する
=================

ではJubatusを起動します。
先ほど説明した通り、Jubatusは複数の機械学習器を持っています。
今日使うのは、分類器(classifier)です。
Jubatusは機械学習器ごとに異なるコマンドで起動します。
分類器は ``jubaclassifier`` コマンドです。

分類器を起動してみましょう。

::

  $ jubaclassifier
  can't start standalone mode without configpath specified
  usage: jubaclassifier [options] ... 
  options:
  ... [略]

Jubatusの各サーバーの起動には、設定ファイルを指定する必要があります。
ターミナルから以下のコマンドを叩いてみてください。

::

  $ jubaclassifier -f /usr/local/share/jubatus/example/config/classifier/pa1.json

.. note::

   0.4.0以前までは、起動後に設定を読み込ませていましたが、0.4.0以降では起動時に指定する必要があります。


``-f`` で指定しているのは設定ファイルです。
デフォルトでサンプルの設定が配布されているので、そのサンプル設定を読み込ませています。
設定に関しては、次の章で解説します。
上記のコマンドでエラーが表示されなければjubaclassifierが起動しています。

起動しなかった場合は、別のプロセスが同じポートを利用している可能性があります。
利用するポートを変えるときは、 ``-p`` オプションを指定します。

::

  $ jubaclassifier -f /usr/local/share/jubatus/example/config/classifier/pa1.json -p 9200

``jubaclassifier`` は学習や予測のクエリ（リクエスト）を受け取るまで、起動した状態で待機します。


サンプルを実行する
==================

``jubaclassifier`` が起動した状態で、サンプルプログラムを実行してみます。
以下のURLからサンプルプログラムをダウンロードしてください。

(TODO: URLは別のに？）
https://gist.github.com/unnonouno/4759954

このサンプルは先ほどの ``jubaclassifier`` へ学習や予測のリクエスト（クエリー）を送信します。
では、実行してみましょう。

::

  $ ./sample.py
  男 0.388551652431
  女 0.473417669535
  
  男 -2.36301612854
  女 2.79595327377

上記のような出力が出たら成功です。


サーバー・クライアントモデル
============================

先のプログラムがどのように動いているのかを通じて、Jubatusの仕組みを解説します。
Jubatusは最初に実行した ``jubaclassifier`` をはじめとするサーバーと、サンプルプログラムを始めとするクライアントからなります。
この仕組みのお陰で、C++で書かれたサーバーがデータの前処理から各種機械学習アルゴリズムの適用を担当し、一方ユーザーサイドのクライアントはPythonやJavaなどの複数の言語のものから選択できます。

TODO 絵を書く

クライアントとサーバー間の通信は、 *msgpack* というデータシリアライズ形式を使った *msgpack-rpc* を利用しています。
各言語用のクライアントライブラリは、msgpack-rpcをラップして隠蔽しているため、ユーザーは何の通信プロトコルを利用しているか知る必要はありません。
クライアントライブラリで用意されているメソッドを呼び出すだけで、自動的に通信を行い、分析結果が得られます。


サンプルプログラムを読んでみる
==============================

ここから自分でプログラムを書けるようにしていきます。
まず手始めに、サンプルプログラムを読んでみます。
非常に単純なサンプルです。

ここでは Python のソースをベースに説明します。
他の言語のサンプルも概ね同じような構造をしています。

::

   client = jubatus.Classifier(host, port)

最初にclassifierのクライアントオブジェクトを作成します。
引数に渡しているのは、サーバーのホスト名とポート番号です。
いずれの言語のライブラリにも、同様なクライアントオブジェクトが存在します。
Jubatusは常にクライアントオブジェクト経由で利用します。

分類器では、まず学習を行いますが、それに関して簡単に説明します。
分類器の学習には、「このデータはこの分類がされます」という *教師データ* を与える必要があります。
教師データは *正解データ* 、 *ラベル付きデータ* と呼ばれることもあります。
最初の行で用意しているのが、この教師データです。
教師データを使って、 ``jubaclassifier`` の ``train`` メソッドを呼び出しています。
``train`` メソッドは、教師データを与えて分類器の構築あるいは更新を行うためのメソッドです。
概ね内部では、「どのようなデータがどのように分類されるのか」という傾向を学習していることになります。

余談ですが ``train`` に渡すデータ構造が複雑なので注意してください。
これは将来的にはもっと使いやすい形になる予定です。
``datum`` というクラス（C++なら struct）のインスタンスを作っています。
以下のようになっているかとおもいます。

::

  datum([(u'髪', u'短髪'), (u'上', u'セーター'), (u'下', 'ジーンズ')], [(u'身長', 1.70)])

ちょっとわかりにくいので、分解して説明します。
``datum`` は単一の教師データを表します。
コンストラクタで2つの引き数を取ります。
1番目が文字列で表現されるデータです。
2番目が数値で表現されるデータです。
いずれもリスト形式（C++なら ``std::vector`` ）で渡します。
各リストは、キーと値のペアの羅列です。
例えば、 ``(u'髪', u'短髪')`` は ``'髪'`` が ``'短髪'`` である、という風に読んでください。
同様に、キーと値のペアを追加していってください。
数値データの方も同様です。
``(u'身長', 1.70)`` となっていれば、 ``'身長'`` が ``1.70`` である、という意味です。
ハッシュや辞書などのデータ構造を使ってないのは実装上の問題ですので、使いにくいですがそういうものだと思ってください。
ここで利用するデータ構造は将来的にもっと使いやすくなる可能性があります。

学習のステップが終わったら、その学習済み分類器を使って未分類のデータを自動分類しています。
``classify`` メソッドは、未分類のデータを分類するためのメソッドです。
今まで学習したデータの傾向に照らしあわせて、学習された基準によって分類を行います。
``classify`` メソッドには、 ``datum`` のリストを渡します。
なお、通信コストを下げるためにリスト形式で一度に複数のデータを渡すようになっています。

それぞれの分類結果は ``classification_result`` という型のリスト形式で返ってきます。
``classification_result`` には ``label`` というメンバ変数と ``score`` というメンバ変数が含まれます。
前者は予測したラベル、後者はそれに対するスコアを示します。
スコアが最大のラベルが、システムの予想だと考えてください。
ソートされて出力されるわけではないので、スコア最大のラベルを探すのは自分でソートする必要があります。
サンプルでは、システムの返した  ``.label`` と ``.score`` を全て出力してます。
1つ目のデータは男性を、2つ目のデータは女性を想定していますから、1つ目のデータに対する分類に失敗しています。

.. note::

   生の結果が返ってきますから、スコアが最大のラベルを探すのはユーザー側で行う必要があります。
   また、スコアは例えば 0 から 1 の間に収まるスコアが出るわけではありません。
   負になることも、数万になることもありますので注意してください。


サンプルを改造してみる
======================

サンプルプログラムの改造を通して、使い方の感触を得ましょう。
一番簡単な改良として、学習データを増やしてみます。
一般的に、学習データは大量にあったほうが分類精度は良くなります。
以下のように、学習データを増やしてみます。

::

  train_data = [
      (u'男', datum([(u'髪', u'短髪'), (u'上', u'セーター'), (u'下', 'ジーンズ')], [(u'身長', 1.70)])),
      (u'女', datum([(u'髪', u'長髪'), (u'上', u'シャツ'), (u'下', 'スカート')], [(u'身長', 1.56)])),
      (u'男', datum([(u'髪', u'短髪'), (u'上', u'ジャケット'), (u'下', 'チノパン')], [(u'身長', 1.65)])),
      (u'女', datum([(u'髪', u'短髪'), (u'上', u'Tシャツ'), (u'下', 'ジーンズ')], [(u'身長', 1.72)])),
      (u'男', datum([(u'髪', u'長髪'), (u'上', u'Tシャツ'), (u'下', 'ジーンズ')], [(u'身長', 1.82)])),
      (u'女', datum([(u'髪', u'長髪'), (u'上', u'ジャケット'), (u'下', 'スカート')], [(u'身長', 1.43)])),
      # 下の2行を追加
      (u'男', datum([(u'髪', u'短髪'), (u'上', u'ジャケット'), (u'下', 'ジーンズ')], [(u'身長', 1.76)])),
      (u'女', datum([(u'髪', u'長髪'), (u'上', u'セーター'), (u'下', 'スカート')], [(u'身長', 1.52)])),
      ]

もう一度同じようにサンプルを実行してください。
実験を繰り返すときは、 ``jubaclassifier`` の再起動もしましょう。
そのまま実行すると、追加学習になります。
実行すると正しく分類できるようになりました。

::

  $ ./sample.py
  男 3.04466104507
  女 -2.1826915741
  
  男 -1.01078510284
  女 1.44372224808


学習データは増やせば増やすほど、基本的には分類精度の向上が期待されます。
ただし、追加したデータが今までと違う傾向があったりすると、精度が向上するどころか下がることもあるので注意しましょう。


次に、ラベルを追加してみます。
今まで"男"と"女"だけの分類でしたが、"男（大人）", "女（大人）", "男（子供）", "女（子供）"の4分類にしてみます。

::

  train_data = [
      (u'男（子供）', datum([(u'髪', u'短髪'), (u'上', u'セーター'), (u'下', 'ジーンズ')], [(u'身長', 1.70)])),
      (u'女（大人）', datum([(u'髪', u'長髪'), (u'上', u'シャツ'), (u'下', 'スカート')], [(u'身長', 1.56)])),
      (u'男（子供）', datum([(u'髪', u'短髪'), (u'上', u'ジャケット'), (u'下', 'チノパン')], [(u'身長', 1.65)])),
      (u'女（大人）', datum([(u'髪', u'短髪'), (u'上', u'Tシャツ'), (u'下', 'ジーンズ')], [(u'身長', 1.72)])),
      (u'男（大人）', datum([(u'髪', u'長髪'), (u'上', u'Tシャツ'), (u'下', 'ジーンズ')], [(u'身長', 1.82)])),
      (u'女（子供）', datum([(u'髪', u'長髪'), (u'上', u'ジャケット'), (u'下', 'スカート')], [(u'身長', 1.43)])),
      (u'男（子供）', datum([(u'髪', u'短髪'), (u'上', u'ジャケット'), (u'下', 'ジーンズ')], [(u'身長', 1.76)])),
      (u'女（子供）', datum([(u'髪', u'長髪'), (u'上', u'セーター'), (u'下', 'スカート')], [(u'身長', 1.52)])),
      ]

先程と同様に実行してみましょう。

::

  $ ./sample.py
  女（大人） -0.560837566853
  男（子供） 1.28676271439
  男（大人） 1.37642300129
  女（子供） -1.24037861824
  
  女（大人） -0.188916295767
  男（子供） -0.478737771511
  男（大人） -0.399394154549
  女（子供） 1.49998533726


一般的にラベル数を増やせば増やすほど、見かけ上の精度は下がることに注意しましょう。
分類の粒度が細かくなればなるほど、正しく当てるのが難しくなるためです。


